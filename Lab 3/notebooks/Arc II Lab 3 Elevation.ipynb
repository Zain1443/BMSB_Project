{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation Accuracy\n",
    "\n",
    "This notebook creates a pipeline which determines both the most accurate interpolation method for a series of elevation points within Minnesota and the accuracy of the point data through comparison of known elevation data. The data is then stored in a file geodatabase and moved to an .sde database for creating real-time web maps in ArcGIS Online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and organize elevation data from SDE database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import arcpy\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import arcgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables for file path\n",
    "file_path = os.path.dirname(arcpy.mp.ArcGISProject('CURRENT').filePath)\n",
    "os.chdir(file_path)\n",
    "\n",
    "# Estabish workspace and spatial reference as WGS 84\n",
    "arcpy.env.workspace = file_path\n",
    "spatial_ref = arcpy.SpatialReference(4326)\n",
    "\n",
    "# Establish variables for project and map\n",
    "project = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "m = project.listMaps(\"Map\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 25, 2024 2:12:47 PM\",\"Succeeded at Monday, March 25, 2024 2:12:48 PM (Elapsed Time: 0.90 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\15612\\\\Documents\\\\Arc II\\\\Lab 3\\\\Lab 3\\\\Lab_3.gdb'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a file GDB to add data to\n",
    "arcpy.management.CreateFileGDB(\n",
    "    out_folder_path = file_path,\n",
    "    out_name = 'Lab_3.gdb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables for the file and SDE GDB path\n",
    "file_gdb = os.path.join(file_path, 'Lab_3.gdb')\n",
    "sde_gdb = os.path.join(file_path, 'PostgreSQL-35-gis5572(postgres).sde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to SDE database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 11, 2024 11:24:01 AM\",\"WARNING 000258: Output C:\\\\Users\\\\15612\\\\Documents\\\\Arc II\\\\Lab 3\\\\Lab 3\\\\PostgreSQL-35-gis5572(postgres).sde already exists\",\"Succeeded at Thursday, April 11, 2024 11:24:09 AM (Elapsed Time: 7.61 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\15612\\\\Documents\\\\Arc II\\\\Lab 3\\\\Lab 3\\\\PostgreSQL-35-gis5572(postgres).sde'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create database connection\n",
    "dbname = 'PostgreSQL-35-gis5572(postgres).sde'\n",
    "platform = 'POSTGRESQL'\n",
    "user = 'postgres'\n",
    "password = 'Hyderabad43%'\n",
    "instance = '35.238.64.215'\n",
    "port = '5432'\n",
    "auth = 'DATABASE_AUTH'\n",
    "save = 'SAVE_USERNAME'\n",
    "db = 'gis5572'\n",
    "\n",
    "arcpy.management.CreateDatabaseConnection(\n",
    "    out_folder_path = file_path,\n",
    "    out_name = dbname,\n",
    "    database_platform = platform,\n",
    "    instance = instance,\n",
    "    account_authentication = auth,\n",
    "    username = user,\n",
    "    password = password,\n",
    "    save_user_pass = save,\n",
    "    database = db\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add \"ground truth\" DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull data from the Minnesota Geospatial Commons\n",
    "def mn_geo_pull_and_unzip(url, directory, GDB_or_SHP):\n",
    "\n",
    "    # Get GeoJSON from MN Geospatial Commons\n",
    "    api = requests.get(url)\n",
    "    json = api.json()\n",
    "    \n",
    "    # Use second list in the 'resources' key if data is in file geodatabase format\n",
    "    if GDB_or_SHP == 'GDB':\n",
    "        zip_link = requests.get(json['result']['resources'][1]['url'])\n",
    "    \n",
    "    # Use first list in the 'resources' key if data is in shapefile format\n",
    "    if GDB_or_SHP == 'SHP':\n",
    "        zip_link = requests.get(json['result']['resources'][2]['url'])\n",
    "    \n",
    "    # Get zipfile and extract\n",
    "    z_file = zipfile.ZipFile(io.BytesIO(zip_link.content))\n",
    "    z_file.extractall(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_geo_pull_and_unzip('https://gisdata.mn.gov/api/3/action/package_show?id=elev-30m-digital-elevation-model',r'C:\\Users\\15612\\Documents\\Arc II\\Lab 3\\Lab 3\\DEM','GDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<arcpy._mp.Layer object at 0x000001BC0204DFD0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.addDataFromPath(r'C:\\Users\\15612\\Documents\\Arc II\\Lab 3\\Lab 3\\DEM\\elev_30m_digital_elevation_model.gdb\\digital_elevation_model_30m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to perform resampling and converting to points\n",
    "arcpy.management.ProjectRaster(\n",
    "    in_raster = r'C:\\Users\\15612\\Documents\\Arc II\\Lab 3\\Lab 3\\DEM\\elev_30m_digital_elevation_model.gdb\\digital_elevation_model_30m',\n",
    "    out_raster = os.path.join(file_gdb,'digital_elevation_model_30m'),\n",
    "    out_coor_system = spatial_ref\n",
    ")\n",
    "\n",
    "# Resample to limit the number of output points\n",
    "arcpy.management.Resample(\n",
    "    in_raster = os.path.join(file_gdb,'digital_elevation_model_30m'),\n",
    "    out_raster = os.path.join(file_gdb,'digital_elevation_model_5km'),\n",
    "    cell_size = 0.139 # About 5 km in vertical degrees\n",
    ")\n",
    "\n",
    "# Establish extent as the size of the ground truth DEM\n",
    "arcpy.env.extent = os.path.join(file_gdb,'digital_elevation_model_5km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from SDE database and adding XY data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting data from SDE database and adding XY data...\")\n",
    "\n",
    "# Define the SDE feature class path\n",
    "sde_feature_class = \"gis5572.postgres.mn_dem_pts\"\n",
    "\n",
    "# Define the local feature class path\n",
    "local_feature_class = r\"C:\\Users\\15612\\Documents\\Arc II\\Lab 3\\Lab 3\\Lab_3.gdb\\MN_DEM_pts\"\n",
    "\n",
    "# Process: Copy Features\n",
    "arcpy.CopyFeatures_management(r\"C:\\Users\\15612\\Documents\\Arc II\\Lab 3\\Lab 3\\PostgreSQL-35-gis5572(postgres).sde\\gis5572.postgres.mn_dem_pts\", local_feature_class)\n",
    "\n",
    "# Add x-coordinate field\n",
    "arcpy.management.AddField(\n",
    "    in_table = os.path.join(file_gdb,'MN_DEM_pts'),\n",
    "    field_name = 'X',\n",
    "    field_type = 'DOUBLE'\n",
    ")\n",
    "\n",
    "# Calculate x-coordinate\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features = os.path.join(file_gdb,'MN_DEM_pts'),\n",
    "    geometry_property = [['X','POINT_X']],\n",
    "    coordinate_system = spatial_ref\n",
    ")\n",
    "  \n",
    "# Add y-coordinate field\n",
    "arcpy.management.AddField(\n",
    "    in_table = os.path.join(file_gdb,'MN_DEM_pts'),\n",
    "    field_name = 'Y',\n",
    "    field_type = 'DOUBLE'\n",
    ")\n",
    "\n",
    "# Calculate y-coordinate\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "    in_features = os.path.join(file_gdb,'MN_DEM_pts'),\n",
    "    geometry_property = [['Y','POINT_Y']],\n",
    "    coordinate_system = spatial_ref\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50/50 Sampling\n",
    "\n",
    "The function below creates a random sample of a specified percentage of points the user inputs for further exploratory interpolation within the notebook. See below for documentation:\n",
    "\n",
    "### create_sample(input_feature_class {str}, x_field {str}, y_field {str}, z_field {str}, percent {float}, gdb_path {str}, out_feature_class {str})\n",
    "- input_feature_class - feature class where the randomly sampled points will be extracted from \n",
    "- id_field - field with ID of each feature\n",
    "- x_field - field with x coordinate\n",
    "- y_field - field with y coordinate\n",
    "- z_field - field with value to be interpolated \n",
    "- percent - ratio of points (in decimal notation) taken from original point feature class \n",
    "- gdb_path - path of geodatabase to save the created feature class to\n",
    "- out_feature_class - name of the output feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elev_sample(input_feature_class, id_field, x_field, y_field, z_field, percent, gdb_path, out_feature_class):\n",
    "    \n",
    "    print('Creating feature class \"' + out_feature_class + '\"...')\n",
    "    \n",
    "    # Create an empty list to add to\n",
    "    all_rows = []\n",
    "    \n",
    "    # Append the XYZ data to the empty list\n",
    "    with arcpy.da.SearchCursor(in_table = input_feature_class, field_names = [id_field, z_field, x_field, y_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            name = row[0]\n",
    "            Z = row[1]\n",
    "            X = row[2]\n",
    "            Y = row[3]\n",
    "            all_rows.append([name, Z, X, Y])\n",
    "\n",
    "    # Establish variables for the number of total rows, the number of samples, and the number of rows outside of the sample rows\n",
    "    total_rows = len(all_rows)\n",
    "    sample_num = int(total_rows * percent)\n",
    "    removed_num = total_rows - sample_num\n",
    "\n",
    "    # Randomize the order of all the rows\n",
    "    random.shuffle(all_rows)\n",
    "    \n",
    "    # Create empty list for XYZ data\n",
    "    name_list = []\n",
    "    Z_list = []\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "\n",
    "    # Add XYZ data to separate lists\n",
    "    for row in all_rows:\n",
    "        name_list.append(row[0])\n",
    "        Z_list.append(row[1])\n",
    "        X_list.append(row[2])\n",
    "        Y_list.append(row[3])\n",
    "\n",
    "    # Remove all of the XYZ data which is not part of the sampled rows\n",
    "    df_list = [name_list, Z_list, X_list, Y_list]\n",
    "    for l in df_list:\n",
    "        del l[-removed_num:]\n",
    "\n",
    "    # Create a dictionary with all XYZ data\n",
    "    rand_dict = {\n",
    "        'ID':name_list,\n",
    "        'Z':Z_list,\n",
    "        'X':X_list,\n",
    "        'Y':Y_list\n",
    "    }\n",
    "\n",
    "    # Create a pandas dataframe from the dictionary\n",
    "    random_sample_df = pd.DataFrame(rand_dict)\n",
    "    \n",
    "    # Convert dataframe to sedf\n",
    "    sedf = arcgis.GeoAccessor.from_xy(\n",
    "        df = random_sample_df, \n",
    "        x_column = \"X\",\n",
    "        y_column = \"Y\"\n",
    "    )\n",
    "\n",
    "    # Convert sedf to feature class\n",
    "    sedf.spatial.to_featureclass(location=os.path.join(gdb_path, out_feature_class))\n",
    "    \n",
    "    # Define projection for the created feature class\n",
    "    arcpy.management.DefineProjection(\n",
    "        in_dataset = out_feature_class,\n",
    "        coor_system = spatial_ref\n",
    "    )\n",
    "    \n",
    "    # Change field type for Z values to 'Float'\n",
    "    arcpy.management.AddField(\n",
    "        in_table = out_feature_class,\n",
    "        field_name = z_field,\n",
    "        field_type = 'FLOAT'\n",
    "    )\n",
    "    \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table = out_feature_class,\n",
    "        field = z_field,\n",
    "        expression = '!z!'\n",
    "    )\n",
    "    \n",
    "    arcpy.management.DeleteField(\n",
    "        in_table = out_feature_class,\n",
    "        drop_field = 'z'\n",
    "    )\n",
    "        \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature class \"Random_Sample_50_elevation\"...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Create a feature class with 20% of random points sampled\n",
    "create_elev_sample(\n",
    "    input_feature_class = 'MN_DEM_pts',\n",
    "    id_field = 'pointid',\n",
    "    x_field = 'X',\n",
    "    y_field = 'Y',\n",
    "    z_field = 'grid_code',\n",
    "    percent = 0.5,\n",
    "    gdb_path = file_gdb,\n",
    "    out_feature_class = 'Random_Sample_50_elevation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 25, 2024 6:34:22 PM\",\"Calculating Ordinary Kriging – Default\",\"Calculating Ordinary Kriging – Optimized\",\"Calculating Universal Kriging – Default\",\"Calculating Universal Kriging – Optimized\",\"Calculating Inverse Distance Weighted - Default\",\"Calculating Inverse Distance Weighted - Optimized\",\" \\n\",\"--------------------------------------------\",\"RANK | NAME\",\"--------------------------------------------\",\"\\n\",\"1    | Universal Kriging – Optimized\",\"\\n\",\"2    | Ordinary Kriging – Optimized\",\"\\n\",\"3    | Universal Kriging – Default\",\"\\n\",\"4    | Ordinary Kriging – Default\",\"\\n\",\"5    | Inverse Distance Weighted - Optimized\",\"\\n\",\"6    | Inverse Distance Weighted - Default\",\"--------------------------------------------\",\"Succeeded at Monday, March 25, 2024 6:34:26 PM (Elapsed Time: 3.18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\15612\\\\Documents\\\\Arc II\\\\Lab 3\\\\Lab 3\\\\Lab_3.gdb\\\\stats_table'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform exploratory interpolation on three different interpolation techniques using random sample\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features = 'Random_Sample_50_elevation',\n",
    "    value_field = 'elevation',\n",
    "    out_cv_table = os.path.join(file_gdb,'stats_table_elevation'),\n",
    "    out_geostat_layer = None,\n",
    "    interp_methods = ['ORDINARY_KRIGING','UNIVERSAL_KRIGING','IDW'],\n",
    "    comparison_method = 'SINGLE',\n",
    "    criterion = 'ACCURACY',\n",
    "    criteria_hierarchy = 'ACCURACY PERCENT #',\n",
    "    weighted_criteria = 'ACCURACY 1',\n",
    "    exclusion_criteria = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary kriging\n",
    "elev_ord_krige = arcpy.sa.Kriging(\n",
    "    in_point_features = 'Random_Sample_50_elevation',\n",
    "    z_field = 'grid_code',\n",
    "    kriging_model = arcpy.sa.KrigingModelOrdinary('SPHERICAL'),\n",
    "    cell_size = 0.139\n",
    ")\n",
    "\n",
    "# Universal kriging\n",
    "elev_uni_krige = arcpy.sa.Kriging(\n",
    "    in_point_features = 'Random_Sample_50_elevation',\n",
    "    z_field = 'grid_code',\n",
    "    kriging_model = arcpy.sa.KrigingModelUniversal('LINEARDRIFT'),\n",
    "    cell_size = 0.139\n",
    ")\n",
    "\n",
    "# Inverse distance weighting\n",
    "elev_IDW = arcpy.sa.Idw(\n",
    "    in_point_features = 'Random_Sample_50_elevation',\n",
    "    z_field = 'grid_code',\n",
    "    cell_size = 0.139\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform accuracy assessment\n",
    "The function below creates points from the sampled and actual rasters created via the interpolations above and compares their Z-values (in this case, daily maximum temperature). The difference between temperature for each point is added to the field named \"temp_difference\" in the output accuracy feature class. The average difference between each temperature is calculated and output as a simple \"print\" statement with the lowest value representing the interpolation method with the highest accuracy.\n",
    "\n",
    "### accuracy_analysis(sampled_interp_layer {str}, complete_interp_layer {str}, output_fc {str})\n",
    "- sampled_interp_layer - the raster layer created via interpolation of the sampled points\n",
    "- complete_interp_layer - the raster layer with the \"ground truth\" data\n",
    "- output_fc - the name of the output feature class with the accuracy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform accuracy analysis and add accuracy data to feature class\n",
    "def accuracy_analysis(sampled_interp_layer,complete_interp_layer,output_fc):\n",
    "\n",
    "    print('Performing accuracy analysis for \"' + sampled_interp_layer + '\" and \"' + complete_interp_layer + '\"...')\n",
    "    \n",
    "    # Create a list of each interpolation layer\n",
    "    interp_layer_list = [sampled_interp_layer,complete_interp_layer]\n",
    "    \n",
    "    # Iterate through each interpolation layer\n",
    "    for layer in interp_layer_list:\n",
    "    \n",
    "        # Turn interpolation data to points\n",
    "        arcpy.conversion.RasterToPoint(\n",
    "            in_raster = layer,\n",
    "            out_point_features = os.path.join(file_gdb,layer + '_points')\n",
    "        )\n",
    "        \n",
    "    # Spatially join all points\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features = os.path.join(file_gdb,sampled_interp_layer + '_points'),\n",
    "        join_features = os.path.join(file_gdb,complete_interp_layer + '_points'),\n",
    "        out_feature_class = os.path.join(file_gdb,output_fc),\n",
    "        match_option = 'CLOSEST'\n",
    "    )\n",
    "    \n",
    "    # Add a field to add the difference values to\n",
    "    arcpy.management.AddField(\n",
    "        in_table = os.path.join(file_gdb,output_fc),\n",
    "        field_name = 'elev_difference',\n",
    "        field_type = 'FLOAT'\n",
    "    )\n",
    "    \n",
    "    # Calculate the difference between the actual and sampled weather station data\n",
    "    try:\n",
    "    \n",
    "        arcpy.management.CalculateField(\n",
    "            in_table = os.path.join(file_gdb,output_fc),\n",
    "            field = 'elev_difference',\n",
    "            expression = 'abs(!grid_code! - !grid_cod_1!)' \n",
    "        )\n",
    "        \n",
    "        arcpy.management.AlterField(\n",
    "            in_table = os.path.join(file_gdb,output_fc),\n",
    "            field = 'grid_cod_1',\n",
    "            new_field_name = 'actual_elev',\n",
    "            new_field_alias = 'actual_elev'\n",
    "        )\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        arcpy.management.CalculateField(\n",
    "            in_table = os.path.join(file_gdb,output_fc),\n",
    "            field = 'elev_difference',\n",
    "            expression = 'abs(!grid_code! - !grid_code_1!)' # Autocreates table with name as \"grid_cod_1\" or \"grid_code_1\"\n",
    "        )\n",
    "        \n",
    "        arcpy.management.AlterField(\n",
    "            in_table = os.path.join(file_gdb,output_fc),\n",
    "            field = 'grid_code_1',\n",
    "            new_field_name = 'actual_elev',\n",
    "            new_field_alias = 'actual_elev'\n",
    "        )\n",
    "    \n",
    "    # Change names of fields to represent data\n",
    "    arcpy.management.AlterField(\n",
    "        in_table = os.path.join(file_gdb,output_fc),\n",
    "        field = 'grid_code',\n",
    "        new_field_name = 'sampled_elev',\n",
    "        new_field_alias = 'sampled_elev'\n",
    "    )\n",
    "    \n",
    "    # Delete excess fields\n",
    "    arcpy.management.DeleteField(\n",
    "        in_table = os.path.join(file_gdb,output_fc),\n",
    "        drop_field = ['Join_Count','TARGET_FID','pointid_1']\n",
    "    )\n",
    "    \n",
    "    # Delete sampled interpolation raster\n",
    "    arcpy.management.Delete(\n",
    "        in_data = os.path.join(file_gdb,sampled_interp_layer + '_points')\n",
    "    )\n",
    "    \n",
    "    # Create empty list to append temperature difference values\n",
    "    elev_dif_list = []\n",
    "    \n",
    "    # Iterate through each row and collect values, then calculate average to find average difference of all values\n",
    "    with arcpy.da.SearchCursor(in_table = os.path.join(file_gdb,output_fc), field_names = 'elev_difference') as cursor:\n",
    "        for row in cursor:\n",
    "            elev_dif_list.append(row[0])\n",
    "            \n",
    "    print('The average elevation difference between \"' + sampled_interp_layer + '\" and \"' + complete_interp_layer + '\" is ' + str(sum(elev_dif_list)/len(elev_dif_list)))\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing accuracy analysis for \"elev_ord_krige\" and \"digital_elevation_model_5km\"...\n",
      "The average elevation difference between \"elev_ord_krige\" and \"digital_elevation_model_5km\" is 90.43442914224265\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy_analysis('elev_ord_krige','digital_elevation_model_5km','elev_ord_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing accuracy analysis for \"elev_uni_krige\" and \"digital_elevation_model_5km\"...\n",
      "The average elevation difference between \"elev_uni_krige\" and \"digital_elevation_model_5km\" is 375.20293396319823\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy_analysis('elev_uni_krige','digital_elevation_model_5km','elev_uni_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing accuracy analysis for \"elev_IDW\" and \"digital_elevation_model_5km\"...\n",
      "The average elevation difference between \"elev_IDW\" and \"digital_elevation_model_5km\" is 110.67556910863073\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "accuracy_analysis('elev_IDW','digital_elevation_model_5km','elev_idw_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Ordinary kriging appears to have the smallest mean difference between point values, meaning it is likely the most accurate when observing elevation values. \n",
    "\n",
    "The points created via IDW interpolation will be added to the SDE database in order to avoid confusion regarding which interpolation was most accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list = ['elev_ord_accuracy','digital_elevation_model_5km_points']\n",
    "\n",
    "for points in points_list:\n",
    "\n",
    "    arcpy.conversion.FeatureClassToGeodatabase(\n",
    "        Input_Features = points,\n",
    "        Output_Geodatabase = sde_gdb\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
